khronus {

  endpoint = "0.0.0.0"
  port = 8400

  windows {
    # delay the current Tick to avoid losing measures pushed out of time
    tick-delay = 1

    # resolutions to be pre calculated
    durations = [30 seconds, 1 minute, 5 minutes, 10 minutes, 30 minutes, 1 hour]
  }

  internal-metrics {
    # all internal metrics has the preffix ~system
    enabled = true

    check-outliers = false
  }

  histogram {
    # expiration ttl
    bucket-retention-policy = 6 hours
    # expiration ttl
    summary-retention-policy = {
      default = 90 days
      overrides = [{ 30 seconds : 15 days, 1 minute : 30 days}]
    }

    bucket-limit = 30000
    bucket-fetch-size = 1000
    summary-limit = 1000
    summary-fetch-size = 200
  }

  counter {
    # expiration ttl
    bucket-retention-policy = 6 hours
    # expiration ttl
    summary-retention-policy = {
      default = 90 days
      overrides = [{ 30 seconds : 15 days, 1 minute : 30 days}]
    }
    bucket-limit = 30000
    bucket-fetch-size = 1000
    summary-limit = 1000
    summary-fetch-size = 200
  }

  master {
    # tick to process all the metrics
    tick-expression = "0/30 * * * * ?"
    check-leader-expression = "0/10 * * * * ?"
    # delay to send discovery (for new workers) message
    discovery-start-delay = 1 second
    discovery-interval = 5 seconds
    worker-batch-size = 5
    max-delay-between-clocks = 2 seconds
  }

  dashboards {
    min-resolution-points = 100
    max-resolution-points = 700
  }

  cassandra {
    cluster {
      name = "KhronusCluster"
      max-connections-per-host = 30
      socket-timeout = 7 seconds
      connection-timeout = 3 seconds
      # useful is you are using an existing cluster
      keyspace-name-suffix = ""
      port = 9042
    }

    meta {
      rf = 3
      insert-chunk-size = 100
    }

    buckets {
      rf = 1
      insert-chunk-size = 100
    }

    summaries {
      rf = 1
      insert-chunk-size = 100
    }

    leader-election {
      rf = 3
    }
  }

  bucket-cache {
    enabled     = true
    max-metrics = {
      timers = 5000
      counters = 10000
      gauges = 5000
    }
    max-store   = 1
    timer       = true
    gauge       = true
    counter     = true
  }
}

akka {
  extensions = ["com.searchlight.khronus.influx.Influx"]

  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = INFO
  stdout-loglevel = INFO

  actor {
    provider = "akka.cluster.ClusterActorRefProvider"

    deployment {
      /master/workers {
        router = round-robin-pool
        supervisor-strategy = "com.searchlight.khronus.cluster.RouterSupervisorStrategy"
        nr-of-instances = 1000
        cluster {
          enabled = on
          max-nr-of-instances-per-node = 100
          allow-local-routees = on
        }
      }
    }
  }

  remote {
    enabled-transports = ["akka.remote.netty.tcp"]
    log-remote-lifecycle-events = on
    netty.tcp {
      # hostname = ${khronus.endpoint}
      port = 9400
      port = ${?CLUSTER_PORT}
    }
  }

  cluster {
    auto-down-unreachable-after = 6 hours
    roles = ["master"]
  }

  # Throughput defines the number of messages that are processed in a batch
  # before the thread is returned to the pool. Set to 1 for as fair as possible.
  # A good idea should be set this with the same as the worker-batch-size in order to process the batch before the thread is released
  actor.default-dispatcher.throughput = 5
}

spray.can.server {
  request-timeout = 3s

  request-chunk-aggregation-limit = 2m
}
